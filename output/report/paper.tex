%
\begin{isabellebody}%
\setisabellecontext{paper}%
%
\isadelimtheory
%
\endisadelimtheory
%
\isatagtheory
%
\endisatagtheory
{\isafoldtheory}%
%
\isadelimtheory
%
\endisadelimtheory
%
\isadelimdocument
%
\endisadelimdocument
%
\isatagdocument
%
\isamarkupsection{Introduction%
}
\isamarkuptrue%
%
\endisatagdocument
{\isafolddocument}%
%
\isadelimdocument
%
\endisadelimdocument
%
\begin{isamarkuptext}%
Leibniz dreamed of modelling all knowledge in the language of formal logic, so that all 
reasoning could be automated. As machines become increasingly capable of mathematical, strategic, 
and scientific reasoning and Leibniz's dream becomes closer to reality, one key gap remains.
Machines lack the ability to perform any meaningful kind of ethical reasoning. Computational 
ethics is a young but attractive field for two primary reasons. First, the proliferation of 
artifically intelligence and autonomous agents is creating and will continue to create a demand for 
ethical autonomous agents. The call for ``ethical AI" can, in one sense, be answered by the creation 
of an automated ethical reasoner. Second, just as automated mathematical reasoning allows mathematicians 
to explore new proofs, automated ethical reasoning is a tool that philosophers can use when reasoning 
about ethics. Many contradictions or paradoxes with an ethical system may not be immediately obvious 
to the human eye, but can be easily tested using an automated theorem prover.

Modelling ethics without sacrificing the intracacies and complexities of an ethical theory is a 
challenging computational and philosophical problem. Many ethical AI systems encode ethics as a series 
of constraints, and they maximize their objective with respect to such constraints. This approach to 
ethics fails to capture much of the complexity of any plausible ethical system. Any faithful model
of an ethical theory will require machinery more complex than a single constraint satisfaction problem.

In addition to the computational machinery, computational ethics also requires a sophisticated 
ethical theory to model. Constraint satisfaction systems often default to some version of utiliarianism, 
the principle of doing the most good for the most people. Alternatively, they model basic moral 
principles such as ``do not kill," without modelling the theory that these principles originated from.
Modelling a more complex ethical theory will not only enable smarter philosophical machines, it will
also empower philosophers to study more complex ethical issues with the computer's help.

The ideal candidate ethical theory will be both philosophically interesting and easy to 
formalize. Kantian ethics, often described as ``formal," is such a candidate. The categorical imperative,
Kant's universal law of morality, is a moral rule that can be used to guide action in all spheres of life.
Kant's original presentation itself is methodical and formal, and the theory lends itself well to 
formalization.

In this paper, I present, implement, and test three formalizations of Kant's categorical imperative 
in the Isabelle/HOL theorem prover. I start with Carmo and Jones' Dyadic Deontic Logic as a base
logic and model each formalization as an extension of DDL. Section 4.3 implements and tests
the naive implementation, a control group that is not much stronger than DDL itself. Section 4.4
examines a more sophisticated implementation inspired by Moshe Kroy's partial formalization of the 
categorical imperative. Section 4.5 explores ????

I contribute implementations of three different interpretations of the categorical imperative, 
examples of how each implementation can be used to model and solve ethical scenarios, and tests that
examine ethical and logical properties of the system, including logical consistency, consistentency
of obligation, and possibility of permissibility. The implementations themselves are usable models 
of ethical principles and the tests represent the kind of philosophical work that formalized ethics 
can contribute.%
\end{isamarkuptext}\isamarkuptrue%
%
\isadelimdocument
%
\endisadelimdocument
%
\isatagdocument
%
\isamarkupsection{System Overview%
}
\isamarkuptrue%
%
\endisatagdocument
{\isafolddocument}%
%
\isadelimdocument
%
\endisadelimdocument
%
\begin{isamarkuptext}%
Formalizing an ethical theory requires a choice of formal language to model the theory in, 
the choice of ethical theory itself, and the choice of theorem prover to implement the formal model.
I use as my base the LogiKEY Workbench \cite{BP} project, a framework for modelling ethics using 
deontic logic. Like LogiKEY, I use Carmo and Jones's Dyadic Deontic Logic \cite{CJDDL}. I focus on 
Kant's categorical imperative, using formalizations inspired by all three formulations of the 
categorical imperative. All the programming is done in Isabelle/HOL.%
\end{isamarkuptext}\isamarkuptrue%
%
\isadelimdocument
%
\endisadelimdocument
%
\isatagdocument
%
\isamarkupsubsection{Dyadic Deontic Logic%
}
\isamarkuptrue%
%
\isamarkupsubsection{Kantian Ethics%
}
\isamarkuptrue%
%
\isamarkupsubsection{Isabelle/HOL%
}
\isamarkuptrue%
%
\isamarkupsection{Details%
}
\isamarkuptrue%
%
\isamarkupsubsection{Naive Implementation/Control Group%
}
\isamarkuptrue%
%
\isamarkupsubsection{Kroy's Partial Formalization%
}
\isamarkuptrue%
%
\isamarkupsection{Related Work%
}
\isamarkuptrue%
%
\isamarkupsection{Conclusion%
}
\isamarkuptrue%
%
\endisatagdocument
{\isafolddocument}%
%
\isadelimdocument
%
\endisadelimdocument
%
\isadelimtheory
%
\endisadelimtheory
%
\isatagtheory
%
\endisatagtheory
{\isafoldtheory}%
%
\isadelimtheory
%
\endisadelimtheory
%
\end{isabellebody}%
\endinput
%:%file=~/Desktop/cs91r/paper.thy%:%
%:%24=6%:%
%:%36=8%:%
%:%37=9%:%
%:%38=10%:%
%:%39=11%:%
%:%40=12%:%
%:%41=13%:%
%:%42=14%:%
%:%43=15%:%
%:%44=16%:%
%:%45=17%:%
%:%46=18%:%
%:%47=19%:%
%:%48=20%:%
%:%49=21%:%
%:%50=22%:%
%:%51=23%:%
%:%52=24%:%
%:%53=25%:%
%:%54=26%:%
%:%55=27%:%
%:%56=28%:%
%:%57=29%:%
%:%58=30%:%
%:%59=31%:%
%:%60=32%:%
%:%61=33%:%
%:%62=34%:%
%:%63=35%:%
%:%64=36%:%
%:%65=37%:%
%:%66=38%:%
%:%67=39%:%
%:%68=40%:%
%:%69=41%:%
%:%70=42%:%
%:%71=43%:%
%:%72=44%:%
%:%73=45%:%
%:%74=46%:%
%:%75=47%:%
%:%76=48%:%
%:%77=49%:%
%:%78=50%:%
%:%79=51%:%
%:%88=53%:%
%:%100=55%:%
%:%101=56%:%
%:%102=57%:%
%:%103=58%:%
%:%104=59%:%
%:%105=60%:%
%:%114=62%:%
%:%118=64%:%
%:%122=66%:%
%:%126=68%:%
%:%130=70%:%
%:%134=72%:%
%:%138=74%:%
%:%142=76%:%